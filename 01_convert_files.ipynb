{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert input data (Jonathan D. MÃ¼ller)\n",
    "\n",
    "Loads the raw data of branch or soil chambers and splits files into daily files in monthly folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization parameters\n",
    "\n",
    "# Data input\n",
    "project_path =  './'\n",
    "\n",
    "project_path_laser = project_path + '01_rawdata/laser computer/'\n",
    "project_path_tc    = project_path + '01_rawdata/thermocouples/'\n",
    "project_path_irga  = project_path + '01_rawdata/irga/'\n",
    "project_path_par   = project_path + '01_rawdata/PAR/'\n",
    "project_path_flow  = project_path + '01_rawdata/flow/'\n",
    "\n",
    "# Output\n",
    "project_path_output = project_path + '02_preprocessed_data/'\n",
    "\n",
    "# List of months to process\n",
    "# - If empty, all available data is processed\n",
    "# - Otherwise, specify using a string of year-month, e.g. ['2018-06'] or ['2017-03','2018-06']\n",
    "month_list = [ '2022-01' ]\n",
    "\n",
    "# Minimum IRGA pump flow\n",
    "# All gas data from the branch chamber IRGA data below this flow will be removed\n",
    "min_irga_flow = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main functions\n",
    "#---------------\n",
    "\n",
    "# Delete all relevant files in a folder.\n",
    "# - Used to remove 1h and 1min monthly files before running to prevent appending to existing files\n",
    "def empty_dir(directory):\n",
    "    files = glob.glob(directory + '*')\n",
    "    for f in files:\n",
    "        month_id = f[-10:-6] + '-' + f[-6:-4]\n",
    "        if(month_id in month_list):\n",
    "            print('Remove ' + f)\n",
    "            os.remove(f)\n",
    "        if(not month_list):\n",
    "            print('Remove ' + f)\n",
    "            os.remove(f)\n",
    "    pass\n",
    "\n",
    "# Read an Aerodyne laser input file, full file\n",
    "def read_laser_file(input_fn):\n",
    "    # Read data\n",
    "    data = [ ]\n",
    "    with open(input_fn) as f:\n",
    "        next(f) # Skip the first line\n",
    "        for line in f:\n",
    "            data.append(re.split(r'\\s', line.strip(), 9))\n",
    "    # build the generator        \n",
    "    for line in data:\n",
    "        if(len(line) < 9):\n",
    "            line.append('')\n",
    "    # first element returned is the columns\n",
    "    columns = ['timestamp','OCS.1','CO2.1','CO2.2','H2O.1','CO2.3','CO.1','OCS.2','CO2.4']\n",
    "    # build the data frame\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    #for index, row in df.iterrows():\n",
    "    #    df.loc[df['timestamp'] == row['timestamp'], 'timestamp'] = float(df.loc[df['timestamp'] == row['timestamp'], 'timestamp'])\n",
    "    df['timestamp'] = pd.to_numeric(df['timestamp'])\n",
    "    # Now apply normal conversions\n",
    "    df['timestamp'] = pd.to_datetime(df.timestamp, unit='s', origin=pd.Timestamp('1904-01-01')) - pd.DateOffset(seconds=1) # To convert IGOR-time (i.e. Excel 1904)\n",
    "    df['dayid'] = df['timestamp'].apply(lambda x:(x.year*10000 + x.month*100 + x.day))\n",
    "    return(df)\n",
    "\n",
    "# Read an Aerodyne laser input file, full file\n",
    "def read_laser_file_by_lines(input_fn, lines):\n",
    "    # Read data\n",
    "    data = [ ]\n",
    "    with open(input_fn) as f:\n",
    "        next(f) # Skip the first line\n",
    "        data.append(re.split(r'\\s', f.readline().strip(), 9))\n",
    "    # build the generator        \n",
    "    for line in data:\n",
    "        if(len(line) < 9):\n",
    "            line.append('')\n",
    "    # first element returned is the columns\n",
    "    columns = ['timestamp','OCS.1','CO2.1','CO2.2','H2O.1','CO2.3','CO.1','OCS.2','CO2.4']\n",
    "    # build the data frame\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    #for index, row in df.iterrows():\n",
    "    #    df.loc[df['timestamp'] == row['timestamp'], 'timestamp'] = float(df.loc[df['timestamp'] == row['timestamp'], 'timestamp'])\n",
    "    df['timestamp'] = pd.to_numeric(df['timestamp'])\n",
    "    # Now apply normal conversions\n",
    "    df['timestamp'] = pd.to_datetime(df.timestamp, unit='s', origin=pd.Timestamp('1904-01-01')) - pd.DateOffset(seconds=1) # To convert IGOR-time (i.e. Excel 1904)\n",
    "    df['dayid'] = df['timestamp'].apply(lambda x:(x.year*10000 + x.month*100 + x.day))\n",
    "    return(df)\n",
    "\n",
    "# OLD Read an Aerodyne laser input file, full file\n",
    "def read_laser_file_old(input_fn):\n",
    "    df = pd.read_csv(input_fn, sep=' ', skiprows=[0], index_col=False, header=0, names=['timestamp','OCS.1','CO2.1','CO2.2','H2O.1','CO2.3','CO.1','OCS.2','CO2.4'])\n",
    "    df['timestamp'] = pd.to_datetime(df.timestamp, unit='s', origin=pd.Timestamp('1904-01-01')) - pd.DateOffset(seconds=1) # To convert IGOR-time (i.e. Excel 1904)\n",
    "    df['dayid'] = df['timestamp'].apply(lambda x:(x.year*10000 + x.month*100 + x.day))\n",
    "    return(df)\n",
    "\n",
    "# OLD Read an Aerodyne laser input file, full file\n",
    "def read_laser_file_by_lines_old(input_fn, lines):\n",
    "    df = pd.read_csv(input_fn, sep=' ', skiprows=[0], nrows=lines, index_col=False, header=0, names=['timestamp','OCS.1','CO2.1','CO2.2','H2O.1','CO2.3','CO.1','OCS.2','CO2.4'])\n",
    "    df['timestamp'] = pd.to_datetime(df.timestamp, unit='s', origin=pd.Timestamp('1904-01-01')) - pd.DateOffset(seconds=1) # To convert IGOR-time (i.e. Excel 1904)\n",
    "    df['dayid'] = df['timestamp'].apply(lambda x:(x.year*10000 + x.month*100 + x.day))\n",
    "    return(df)\n",
    "\n",
    "# Read a CR1000 input file, full file\n",
    "def read_cr1000_file(input_fn):\n",
    "    df = pd.read_csv(input_fn,skiprows=[0,2,3,4,5], na_values=[\"NAN\"])\n",
    "    if(df.columns[0] != 'TIMESTAMP'):\n",
    "        df = pd.read_csv(input_fn,skiprows=[0,1,3,4,5,6], na_values=[\"NAN\"])\n",
    "    df.rename(columns={'TIMESTAMP':'timestamp'}, inplace=True)\n",
    "    df['timestamp'] = pd.to_datetime( df.timestamp, format='%Y-%m-%d %H:%M:%S', utc=True, errors=\"raise\")#errors='coerce')\n",
    "    df['dayid'] = df['timestamp'].apply(lambda x:(x.year*10000 + x.month*100 + x.day))\n",
    "    return(df)\n",
    "\n",
    "# Read a CR1000 input file by lines, only some initial lines\n",
    "def read_cr1000_file_by_lines(input_fn, lines):\n",
    "    df = pd.read_csv(input_fn,skiprows=[0,2,3,4], na_values=[\"NAN\"],nrows=lines)\n",
    "    if(df.columns[0] != 'TIMESTAMP'):\n",
    "        df = pd.read_csv(input_fn,skiprows=[0,1,3,4,5], na_values=[\"NAN\"],nrows=lines)\n",
    "    df.rename(columns={'TIMESTAMP':'timestamp'}, inplace=True)\n",
    "    df['timestamp'] = pd.to_datetime( df.timestamp, format='%Y-%m-%d %H:%M:%S', utc=True, errors=\"raise\")#errors='coerce')\n",
    "    df['dayid'] = df['timestamp'].apply(lambda x:(x.year*10000 + x.month*100 + x.day))\n",
    "    return(df)\n",
    "\n",
    "# Read a CR1000 input file, full file\n",
    "def read_irga_file(input_fn):\n",
    "    df = pd.read_csv(input_fn,skiprows=[0,2,3,4,5], na_values=[\"NAN\"])\n",
    "    if(df.columns[0] != 'TIMESTAMP'):\n",
    "        df = pd.read_csv(input_fn,skiprows=[0,1,3,4,5,6], na_values=[\"NAN\"])\n",
    "    df.rename(columns={'TIMESTAMP':'timestamp'}, inplace=True)\n",
    "    df['timestamp'] = pd.to_datetime( df.timestamp, format='%Y-%m-%d %H:%M:%S', utc=True, errors=\"raise\")#errors='coerce')\n",
    "    df['dayid'] = df['timestamp'].apply(lambda x:(x.year*10000 + x.month*100 + x.day))\n",
    "    return(df)\n",
    "\n",
    "# Read a CR1000 input file by lines\n",
    "def read_irga_file_by_lines(input_fn, lines):\n",
    "    df = pd.read_csv(input_fn,skiprows=[0,2,3,4], na_values=[\"NAN\"],nrows=lines)\n",
    "    if(df.columns[0] != 'TIMESTAMP'):\n",
    "        df = pd.read_csv(input_fn,skiprows=[0,1,3,4,5], na_values=[\"NAN\"],nrows=lines)\n",
    "    df.rename(columns={'TIMESTAMP':'timestamp'}, inplace=True)\n",
    "    df['timestamp'] = pd.to_datetime( df.timestamp, format='%Y-%m-%d %H:%M:%S', utc=True, errors=\"raise\")#errors='coerce')\n",
    "    df['dayid'] = df['timestamp'].apply(lambda x:(x.year*10000 + x.month*100 + x.day))\n",
    "    return(df)\n",
    "\n",
    "def remove_obsolete_irga_data(temp):\n",
    "    temp = temp.copy()\n",
    "    \n",
    "    # Rename PAR & temperature\n",
    "    temp.rename(columns={'RadKipZonen':'par.ambient.umol_m2_s1'}, inplace=True)\n",
    "    temp.rename(columns={'Tc(8)':'temp.air.ambient.c'}, inplace=True)\n",
    "    temp.rename(columns={'H2o_6262_mmol_mol':'h2o.irga.ambient.mmol_mol'}, inplace=True)\n",
    "    temp.rename(columns={'Co2_6262_micmol_mol':'co2.irga.ambient.umol_mol'}, inplace=True)\n",
    "    temp.rename(columns={'AirFlow_Amb':'pump.flow.irga.lpm'}, inplace=True)\n",
    "    temp.rename(columns={'Prees_7000':'P.irga.kPa'}, inplace=True)\n",
    "    \n",
    "    # Remove bad data\n",
    "    temp.loc[temp['pump.flow.irga.lpm'] <= min_irga_flow, 'h2o.irga.ambient.mmol_mol'] = np.nan\n",
    "    temp.loc[temp['pump.flow.irga.lpm'] <= min_irga_flow, 'co2.irga.ambient.umol_mol'] = np.nan\n",
    "    \n",
    "    # Keep only relevant columns\n",
    "    temp = temp[['timestamp','temp.air.ambient.c','par.ambient.umol_m2_s1','h2o.irga.ambient.mmol_mol','co2.irga.ambient.umol_mol','P.irga.kPa','dayid']]\n",
    "    \n",
    "    return(temp)\n",
    "\n",
    "# Writes output files in full temporal resolution\n",
    "def write_output_file(out_df, date_idx, out_dir, output_fn):\n",
    "    out_df = out_df.copy()\n",
    "    # Drop duplicates\n",
    "    out_df.drop_duplicates(subset = 'timestamp', inplace=True)\n",
    "    # Sort, in case it's not yet the case\n",
    "    out_df.sort_values('timestamp', inplace=True)\n",
    "    \n",
    "    # Check if output folders exist. If not, create\n",
    "    month_dir = str(date_idx)[0:4] + \"-\" + str(date_idx)[4:6]\n",
    "    if(not os.path.exists(out_dir + month_dir)): # make directory if it doesn't exist\n",
    "        os.makedirs(out_dir + month_dir)\n",
    "    # Create file name\n",
    "    out_fn = out_dir + month_dir + \"/\" + output_fn + \"_\" + str(date_idx) + \".csv\"\n",
    "    #print(str(len(out_df.dayid)), out_fn) # Shows final file size)\n",
    "    # organise data for output\n",
    "    temp_df = out_df\n",
    "    # Before saving, remove the index\n",
    "    temp_df.drop('dayid', axis=1, inplace=True)\n",
    "    # Move timestamp column to the front\n",
    "    col = temp_df.pop('timestamp')\n",
    "    temp_df.insert(0, col.name, col, allow_duplicates=True)\n",
    "    # Remove timezone information\n",
    "    temp_df['timestamp'] = temp_df['timestamp'].dt.tz_localize(None)\n",
    "    # Write data\n",
    "    temp_df.to_csv(out_fn, index=False, encoding='utf-8', date_format='%Y-%m-%d %H:%M:%S') # Save file\n",
    "    \n",
    "# Creates a daily file for each type\n",
    "def organise_files(project_path, output_path, filetype):\n",
    "    # List all files in the directories\n",
    "    fn_list = sorted(glob.glob(project_path + '*/*', recursive=True))\n",
    "    if(filetype == 'laser'):\n",
    "        fn_list = sorted(glob.glob(project_path + '*/*.str', recursive=True))\n",
    "    saved = []\n",
    "    \n",
    "    # Create output path name\n",
    "    project_path_output = output_path + project_path.split('/')[-2] + '/'\n",
    "\n",
    "    # For all files in the directory\n",
    "    for fn_i, fn in enumerate(fn_list):\n",
    "        # Only run data in the month list\n",
    "        current_month = fn.replace(project_path[:-1], \"\")[1:8]\n",
    "        if((current_month in month_list) or (len(month_list) == 0)):\n",
    "            if( (filetype == 'irga') & (int(current_month.replace('-','')) < 202007) ):\n",
    "                continue\n",
    "            #display(fn.replace(project_path_chambers[:-1], \"\")[1:8])\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # Debugging message\n",
    "        if(fn_i % 1 == 0): # % 20 to show every 20th file being loaded\n",
    "            print( '{:<07}'.format(str(round(fn_i * 100 / len(fn_list), 4))) + \"%\\t\\t\" + fn.split('\\\\')[-2] + '/' + fn.split('\\\\')[-1]) # Show status\n",
    "            #print( '{:<07}'.format(str(round(fn_i * 100 / len(fn_list), 4))) + \"%\\t\\t\" + fn.replace(project_path + \"01_rawdata/\", \"\")) # Show status\n",
    "    \n",
    "        # Load the current laser file\n",
    "        if(filetype == 'laser'):\n",
    "            df = read_laser_file(fn)\n",
    "        else:\n",
    "            df = read_cr1000_file(fn)\n",
    "            if(filetype == 'irga'):\n",
    "                df = remove_obsolete_irga_data(df)\n",
    "                project_path_output = output_path + 'ambient/'\n",
    "    \n",
    "        if (fn_i != len(fn_list)-1):\n",
    "            # Load next file\n",
    "            if(filetype == 'laser'):\n",
    "                df_next = read_laser_file_by_lines(fn_list[fn_i+1], lines=1)\n",
    "            else:\n",
    "                df_next = read_cr1000_file_by_lines(fn_list[fn_i+1], lines=1)\n",
    "            next_day = df_next['dayid'].tolist()[0]\n",
    "            final_file = False\n",
    "        else:\n",
    "            next_day = 0\n",
    "            final_file = True\n",
    "  \n",
    "        # Group by per-day id\n",
    "        grouped = df.groupby(['dayid'])\n",
    "        #print(\"    Days in this file:  \", len(grouped))\n",
    "    \n",
    "        # For each group\n",
    "        for group_i, (this_day, day) in enumerate(grouped):\n",
    "        \n",
    "            # If we have saved data and if the day matches append the current\n",
    "            if (len(saved) > 0):\n",
    "                if (this_day == saved['dayid'].tolist()[0]):\n",
    "                    day = pd.concat([saved, day], axis=0, ignore_index=True)\n",
    "                    #print(\"    Current line count: \", str(len(day.dayid)))\n",
    "        \n",
    "            #If this is the final group in the file and this is not the final file and the first group of the next file is the same day\n",
    "            if (group_i == len(grouped)-1) and (not final_file) and (this_day == next_day):\n",
    "                saved = day\n",
    "                continue  \n",
    "            else:\n",
    "                write_output_file(day, this_day, project_path_output, filetype)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert files to daily output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run calculations\n",
    "#-----------------\n",
    "\n",
    "print('Laser files')\n",
    "organise_files(project_path_laser, project_path_output, 'laser')\n",
    "\n",
    "print(\"Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PAR files')\n",
    "organise_files(project_path_par, project_path_output, 'par')\n",
    "\n",
    "print(\"Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Thermocouple files')\n",
    "organise_files(project_path_tc, project_path_output, 'tc')\n",
    "\n",
    "print(\"Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Flow rate files')\n",
    "organise_files(project_path_flow, project_path_output, 'flow')\n",
    "\n",
    "print(\"Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRGA files needed for the ambient data. There is a lot, so it's slow...\n",
    "print('IRGA files')\n",
    "organise_files(project_path_irga, project_path_output, 'irga')\n",
    "\n",
    "print(\"Done...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing data replacement\n",
    "\n",
    "There were gaps in the measurements due to device failure. Data was considered to be stable during this time period and was therefore replaced as follows:\n",
    "\n",
    "- FR gap:    [started at 11th July 2021 end 7th Aug 2021], we will use 10th July 2021 for July days, and 9th Aug 2021 for Aug days  \n",
    "- Tc gap:    [started at 13th July 2021 end 23rd July 2021], we will use 11th July 2021 for July days\n",
    "- PAR gap:   [started at 11th July 2021 end 7th Aug 2021], we will use 10th July 2021 for July days, and 8th Aug 2021 for Aug days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace bad Tc, July 2021\n",
    "\n",
    "# Read input file\n",
    "input_fn = project_path_output + 'thermocouples/' + '2021-07/tc_20210711.csv'\n",
    "print(input_fn)\n",
    "input_df = pd.read_csv(input_fn)\n",
    "input_df['timestamp'] = pd.to_datetime(input_df.timestamp, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Calculate number of days offset\n",
    "days_offset = str(input_df['timestamp'].dt.day.values[0] - 1) + 'days'\n",
    "current_month = input_df['timestamp'].dt.month.values[0]\n",
    "input_df['timestamp'] = input_df['timestamp'] - pd.Timedelta(days_offset)\n",
    "\n",
    "# July\n",
    "for i in np.arange(14, 23):\n",
    "    out_df = input_df.copy()\n",
    "    out_df['timestamp'] = out_df['timestamp'] + pd.Timedelta(str(i-1) + 'day')\n",
    "    out_df['dayid'] = 2021*10000 + current_month*100 + i\n",
    "    date_idx = 2021*10000 + current_month*100 + i\n",
    "    print(date_idx)\n",
    "    write_output_file(out_df, date_idx, project_path_output + 'thermocouples/', 'tc')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace bad flow, July 2021\n",
    "\n",
    "# Read input file\n",
    "input_fn = project_path_output + 'flow/' + '2021-07/flow_20210710.csv'\n",
    "print(input_fn)\n",
    "input_df = pd.read_csv(input_fn)\n",
    "input_df['timestamp'] = pd.to_datetime(input_df.timestamp, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Calculate number of days offset\n",
    "days_offset = str(input_df['timestamp'].dt.day.values[0] - 1) + 'days'\n",
    "current_month = input_df['timestamp'].dt.month.values[0]\n",
    "input_df['timestamp'] = input_df['timestamp'] - pd.Timedelta(days_offset)\n",
    "\n",
    "# July\n",
    "for i in np.arange(11, 32):\n",
    "    out_df = input_df.copy()\n",
    "    out_df['timestamp'] = out_df['timestamp'] + pd.Timedelta(str(i-1) + 'day')\n",
    "    out_df['dayid'] = 2021*10000 + current_month*100 + i\n",
    "    date_idx = 2021*10000 + current_month*100 + i\n",
    "    print(date_idx)\n",
    "    write_output_file(out_df, date_idx, project_path_output + 'flow/', 'flow')\n",
    "    pass\n",
    "\n",
    "# Replace bad flow, Aug 2021\n",
    "\n",
    "# Read input file\n",
    "input_fn = project_path_output + 'flow/' + '2021-08/flow_20210809.csv'\n",
    "print(input_fn)\n",
    "input_df = pd.read_csv(input_fn)\n",
    "input_df['timestamp'] = pd.to_datetime(input_df.timestamp, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Calculate number of days offset\n",
    "days_offset = str(input_df['timestamp'].dt.day.values[0] - 1) + 'days'\n",
    "current_month = input_df['timestamp'].dt.month.values[0]\n",
    "input_df['timestamp'] = input_df['timestamp'] - pd.Timedelta(days_offset)\n",
    "\n",
    "# July\n",
    "for i in np.arange(1, 8):\n",
    "    out_df = input_df.copy()\n",
    "    out_df['timestamp'] = out_df['timestamp'] + pd.Timedelta(str(i-1) + 'day')\n",
    "    out_df['dayid'] = 2021*10000 + current_month*100 + i\n",
    "    date_idx = 2021*10000 + current_month*100 + i\n",
    "    print(date_idx)\n",
    "    write_output_file(out_df, date_idx, project_path_output + 'flow/', 'flow')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace bad PAR, July 2021\n",
    "\n",
    "# Read input file\n",
    "input_fn = project_path_output + 'PAR/' + '2021-07/par_20210710.csv'\n",
    "print(input_fn)\n",
    "input_df = pd.read_csv(input_fn)\n",
    "input_df['timestamp'] = pd.to_datetime(input_df.timestamp, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Calculate number of days offset\n",
    "days_offset = str(input_df['timestamp'].dt.day.values[0] - 1) + 'days'\n",
    "current_month = input_df['timestamp'].dt.month.values[0]\n",
    "input_df['timestamp'] = input_df['timestamp'] - pd.Timedelta(days_offset)\n",
    "\n",
    "# July\n",
    "for i in np.arange(12, 32):\n",
    "    out_df = input_df.copy()\n",
    "    out_df['timestamp'] = out_df['timestamp'] + pd.Timedelta(str(i-1) + 'day')\n",
    "    out_df['dayid'] = 2021*10000 + current_month*100 + i\n",
    "    date_idx = 2021*10000 + current_month*100 + i\n",
    "    print(date_idx)\n",
    "    write_output_file(out_df, date_idx, project_path_output + 'PAR/', 'par')\n",
    "    pass\n",
    "\n",
    "# Replace bad PAR, Aug 2021\n",
    "\n",
    "# Read input file\n",
    "input_fn = project_path_output + 'PAR/' + '2021-08/par_20210808.csv'\n",
    "print(input_fn)\n",
    "input_df = pd.read_csv(input_fn)\n",
    "input_df['timestamp'] = pd.to_datetime(input_df.timestamp, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Calculate number of days offset\n",
    "days_offset = str(input_df['timestamp'].dt.day.values[0] - 1) + 'days'\n",
    "current_month = input_df['timestamp'].dt.month.values[0]\n",
    "input_df['timestamp'] = input_df['timestamp'] - pd.Timedelta(days_offset)\n",
    "\n",
    "# July\n",
    "for i in np.arange(1, 8):\n",
    "    out_df = input_df.copy()\n",
    "    out_df['timestamp'] = out_df['timestamp'] + pd.Timedelta(str(i-1) + 'day')\n",
    "    out_df['dayid'] = 2021*10000 + current_month*100 + i\n",
    "    date_idx = 2021*10000 + current_month*100 + i\n",
    "    print(date_idx)\n",
    "    #display(out_df)\n",
    "    write_output_file(out_df, date_idx, project_path_output + 'PAR/', 'par')\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
